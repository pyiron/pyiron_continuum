{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "530d4134-08d9-4cf6-8e40-05cb2b106957",
   "metadata": {},
   "source": [
    "# DAMASK tutorial\n",
    "\n",
    "- creating necessary inputs for damask\n",
    "- defining the elastoplastic model (with powerlaw) for tensile test\n",
    "- runing the damask jobs\n",
    "\n",
    "here more option is given to the user to select from damask python package itself.\n",
    "\n",
    "Author: Yang Bai\n",
    "\n",
    "Date  : 23.02.2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413799b5-58a8-47d3-bfd1-d081c1f2c4ec",
   "metadata": {},
   "source": [
    "## Importing libraries and creatign Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12795c73-ee40-4a15-8e52-60edc207fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_continuum import Project\n",
    "from damask import Rotation # this will be used in material configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de196129-3f7b-4b70-863b-3a762f116877",
   "metadata": {},
   "source": [
    "### create a 'project' to manage all the configurations for a tensile test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "435b1538-9181-4223-a475-aa338c8b09da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393ed1bb04f54dcb9e8e4c742299ca3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr = Project('powerlaw') # automatically delete the existing project folder\n",
    "pr.remove_jobs(silently=True) # automatically delete the existing project folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c7dc7e-c88b-483b-9a82-e149dbe6f435",
   "metadata": {},
   "source": [
    "### Creating the Damask job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7080422-6e97-48d7-8b76-f97f20eb32c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = pr.create.job.DAMASK('damask_job')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30c5306-836f-4f96-93a0-4104e4a6afeb",
   "metadata": {},
   "source": [
    "#### for a damask job, one needs:\n",
    "- geometry information(i.e., the mesh)\n",
    "- material configuration(material.yaml)\n",
    "- boundary conditions(i.e., loading.yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b538216c-f561-481c-b74d-3e702af56cb6",
   "metadata": {},
   "source": [
    "#### for the number of grains and grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b7fb4d3-ad36-4576-9299-0e72d42fa4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grains=4;grids=16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7d3a58-e559-4a60-8777-76292837a8e1",
   "metadata": {},
   "source": [
    "### For material configuration\n",
    "#### for elastoplastic material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d5b9320-b0ff-4b28-ba2a-9dea93e67f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticity = pr.continuum.damask.Elasticity(type= 'Hooke', C_11= 106.75e9,\n",
    "                                   C_12= 60.41e9, C_44=28.34e9)\n",
    "plasticity = pr.continuum.damask.Plasticity(type='phenopowerlaw',\n",
    "                                            N_sl=[12],a_sl=[2.25],\n",
    "                                            atol_xi=1.0,dot_gamma_0_sl=[0.001],\n",
    "                                            h_0_sl_sl=[75.0e6],\n",
    "                                            h_sl_sl=[1, 1, 1.4, 1.4, 1.4, 1.4, 1.4],\n",
    "                                            n_sl=[20],\n",
    "                                            output=['xi_sl'],\n",
    "                                            xi_0_sl=[31.0e6],\n",
    "                                            xi_inf_sl=[63.0e6]\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a214949-102d-4343-90be-1b0a4b8f0818",
   "metadata": {},
   "source": [
    "#### for material configuration, you need\n",
    "- phase\n",
    "- roation\n",
    "- homogenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46f5a2f0-4082-473e-953a-c5a0cb48a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = pr.continuum.damask.Phase(composition='Aluminum', lattice= 'cF',\n",
    "                         output_list=['F', 'P', 'F_e', 'F_p', 'L_p', 'O'],\n",
    "                         elasticity=elasticity,plasticity=plasticity)\n",
    "rotation = pr.continuum.damask.Rotation(Rotation.from_random, grains)\n",
    "\n",
    "homogenization = pr.continuum.damask.Homogenization(method='SX', \n",
    "                                                     parameters={'N_constituents': 1,\n",
    "                                                                 \"mechanical\": {\"type\": \"pass\"}})\n",
    "\n",
    "# now you can define your material.yaml configuration\n",
    "material = pr.continuum.damask.Material([rotation],['Aluminum'], phase, homogenization)\n",
    "\n",
    "# now you can save your material to your job\n",
    "job.material = material"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b485772d-5c31-44df-a8b5-0faefaaafa5e",
   "metadata": {},
   "source": [
    "## For geometry information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c804ec6-476e-4f9c-bfc0-95e2d3a282f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = pr.continuum.damask.Grid.via_voronoi_tessellation(box_size=1.0e-5, spatial_discretization=grids, num_grains=grains)\n",
    "\n",
    "# save the geometry information to your job\n",
    "job.grid = grid "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1243eb3-a38d-4f36-a363-4e878d4d2cea",
   "metadata": {},
   "source": [
    "## For boundary conditions (loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e45ef751-39aa-4cc4-8835-47ef256620d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_step =[{'mech_bc_dict':{'dot_F':[1e-3,0,0, 0,'x',0,  0,0,'x'],\n",
    "                            'P':['x','x','x', 'x',0,'x',  'x','x',0]},\n",
    "            'discretization':{'t': 10.,'N': 40},\n",
    "            'additional': {'f_out': 4}\n",
    "           },{'mech_bc_dict':{'dot_F':[1e-3,0,0, 0,'x',0,  0,0,'x'],\n",
    "                              'P':['x','x','x', 'x',0,'x',  'x','x',0]},\n",
    "            'discretization':{'t': 60.,'N': 60},\n",
    "            'additional': {'f_out': 4}\n",
    "           }]\n",
    "solver = job.list_solvers()[0] # choose the mechanis solver\n",
    "job.loading = pr.continuum.damask.Loading(solver=solver, load_steps=load_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dd97049-00a3-4e11-8077-8f18a958ee49",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# running your job, if you want the parallelization you can modify your 'pyiron/damask/bin/run_damask_3.0.0.sh file'\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/pyiron_base/pyiron_base/utils/deprecate.py:171\u001b[0m, in \u001b[0;36mDeprecator.__deprecate_argument.<locals>.decorated\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kw \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marguments:\n\u001b[1;32m    162\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    163\u001b[0m             message_format\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    164\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    170\u001b[0m         )\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/pyiron_base/pyiron_base/jobs/job/generic.py:763\u001b[0m, in \u001b[0;36mGenericJob.run\u001b[0;34m(self, delete_existing_job, repair, debug, run_mode, run_again)\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_if_repair()\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m status \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_if_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m status \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_if_created()\n",
      "File \u001b[0;32m~/dev/pyiron_base/pyiron_base/jobs/job/generic.py:1281\u001b[0m, in \u001b[0;36mGenericJob._run_if_new\u001b[0;34m(self, debug)\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_if_new\u001b[39m(\u001b[38;5;28mself\u001b[39m, debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;124;03m    Internal helper function the run if new function is called when the job status is 'initialized'. It prepares\u001b[39;00m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;124;03m    the hdf5 file and the corresponding directory structure.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;124;03m        debug (bool): Debug Mode\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1281\u001b[0m     \u001b[43mrun_job_with_status_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/pyiron_base/pyiron_base/jobs/job/runfunction.py:91\u001b[0m, in \u001b[0;36mrun_job_with_status_initialized\u001b[0;34m(job, debug)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exists already and therefore was not created!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m     \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     job\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/dev/pyiron_base/pyiron_base/jobs/job/generic.py:1153\u001b[0m, in \u001b[0;36mGenericJob.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_if_input_should_be_written():\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproject_hdf5\u001b[38;5;241m.\u001b[39mcreate_working_directory()\n\u001b[0;32m-> 1153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m     _copy_restart_files(job\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mcreated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/pyiron_continuum/pyiron_continuum/damask/damaskjob.py:126\u001b[0m, in \u001b[0;36mwrite_input\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcollect_output\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_results()\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mdamask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results\n",
      "File \u001b[0;32m~/dev/pyiron_continuum/pyiron_continuum/damask/damaskjob.py:113\u001b[0m, in \u001b[0;36m_write_material\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_write_loading\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 113\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworking_directory, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput\u001b[38;5;241m.\u001b[39mloading\u001b[38;5;241m.\u001b[39msave(file_path)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "job.run() # running your job, if you want the parallelization you can modify your 'pyiron/damask/bin/run_damask_3.0.0.sh file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b08ec-9259-45bf-ae16-da2792f8c5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the strain_xx vs stress_xx profile\n",
    "job.plot_stress_strain(component='zz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ce390e-4d54-4a59-8940-cf74896054dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the vonMises-strain vs vonMises-stress profile\n",
    "job.plot_stress_strain(von_mises=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyiron",
   "language": "python",
   "name": "pyiron"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
